{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fc4fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bebca619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2  \n",
    "\n",
    "data_folder = \"Dataset\"\n",
    "image_files = os.listdir(data_folder)\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for filename in image_files:\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        # Extract class label from filename\n",
    "        label = int(filename.split(\"_\")[-1].split(\".\")[0])\n",
    "        labels.append(label)\n",
    "        image_path = os.path.join(data_folder, filename)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) \n",
    "        resized_image = cv2.resize(image, (64, 64))  # Resize image to 64x64 pixels\n",
    "        image_flat = resized_image.flatten()  # Flatten resized image into 1D array\n",
    "        images.append(image_flat)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdbfccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA of different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c36159d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit 0: [[ 0.00382001  0.00315794 -0.02943456 ... -0.0125611   0.03058755\n",
      "   0.00013395]\n",
      " [ 0.00232613 -0.00453058 -0.05569537 ... -0.01115975  0.01281268\n",
      "   0.01054267]\n",
      " [ 0.00191541 -0.00534298 -0.05464407 ... -0.00593539  0.00045497\n",
      "   0.0092326 ]\n",
      " ...\n",
      " [-0.0085644  -0.00612617  0.0596254  ...  0.00631146 -0.01843602\n",
      "  -0.01074692]\n",
      " [-0.00790281 -0.02184084  0.06018267 ...  0.00843367 -0.026376\n",
      "  -0.0100369 ]\n",
      " [-0.00499384 -0.04077886  0.04751378 ...  0.00488013 -0.02370819\n",
      "  -0.00482705]] principal components\n",
      "Digit 1: [[-0.00296788 -0.03448859  0.02623855 ... -0.00938445  0.0120235\n",
      "  -0.03369139]\n",
      " [-0.00187911 -0.02844298  0.05346614 ... -0.00368034  0.00076127\n",
      "  -0.01582934]\n",
      " [-0.00129918 -0.02509976  0.05498393 ... -0.01005978 -0.00579222\n",
      "  -0.00169468]\n",
      " ...\n",
      " [ 0.00838189  0.02817118  0.04769521 ... -0.00235915 -0.00123341\n",
      "   0.00629348]\n",
      " [ 0.00773648  0.03529188  0.04984223 ... -0.00216969  0.00411809\n",
      "   0.00858943]\n",
      " [ 0.00708436  0.04674492  0.04260313 ...  0.01180711 -0.00323333\n",
      "   0.00027075]] principal components\n",
      "Digit 2: [[ 4.23079479e-03  4.85513498e-03 -2.53592233e-02 ... -7.68589012e-03\n",
      "   3.74873997e-03  3.33100846e-02]\n",
      " [ 3.07369039e-03  9.42601730e-04 -6.74264481e-02 ... -5.35952160e-03\n",
      "   4.98685769e-03  8.42704526e-03]\n",
      " [ 2.73830091e-03 -3.13041741e-05 -6.74112084e-02 ... -5.51603142e-03\n",
      "   5.43550648e-03 -2.63970535e-04]\n",
      " ...\n",
      " [-7.28718136e-03 -1.39664210e-03  2.33452216e-02 ...  8.99748865e-03\n",
      "  -1.76256138e-03  8.15923724e-03]\n",
      " [-6.10998662e-03 -2.22646844e-02  2.52469616e-02 ...  6.62389930e-03\n",
      "   1.53709378e-04  4.39488862e-03]\n",
      " [-3.68037412e-03 -4.44564861e-02  1.59069631e-02 ...  3.92919547e-03\n",
      "   8.76927263e-03 -3.88326226e-03]] principal components\n",
      "Digit 3: [[ 0.00543034  0.00101944 -0.04188811 ...  0.02707604 -0.01499392\n",
      "   0.01296044]\n",
      " [ 0.00445364 -0.00975293 -0.05575554 ...  0.00739534 -0.00468186\n",
      "   0.00431213]\n",
      " [ 0.00386251 -0.01091434 -0.05654992 ... -0.00010759 -0.00316279\n",
      "   0.00048979]\n",
      " ...\n",
      " [-0.01437792 -0.00205998  0.02348042 ...  0.00933316 -0.00880967\n",
      "   0.0044273 ]\n",
      " [-0.01155864 -0.02410728  0.02415316 ...  0.0195261   0.00934981\n",
      "   0.01119709]\n",
      " [-0.00709397 -0.04484057  0.0128158  ...  0.02788988  0.0310814\n",
      "   0.02473662]] principal components\n",
      "Digit 4: [[-0.00171945 -0.03063752  0.04399234 ... -0.01844545 -0.00881733\n",
      "   0.0160379 ]\n",
      " [-0.00134762 -0.02626738  0.04906592 ... -0.02406764 -0.00126581\n",
      "   0.00617074]\n",
      " [-0.00139982 -0.02145508  0.04990529 ... -0.02099349 -0.0011621\n",
      "  -0.00072639]\n",
      " ...\n",
      " [ 0.01152757 -0.00086284  0.01749144 ...  0.00530737 -0.00151383\n",
      "  -0.00917075]\n",
      " [ 0.00929217  0.02174915  0.03269616 ...  0.01052683  0.01128989\n",
      "  -0.01563519]\n",
      " [ 0.00512096  0.03987199  0.03284428 ...  0.01487701  0.021362\n",
      "  -0.01816273]] principal components\n",
      "Digit 5: [[-0.00485546 -0.01265364  0.04368147 ... -0.03849917  0.00615406\n",
      "   0.00508965]\n",
      " [-0.00352976 -0.00242106  0.05741321 ... -0.01164557  0.00065536\n",
      "   0.00163194]\n",
      " [-0.00278675  0.00064719  0.05711164 ... -0.00312072 -0.00057391\n",
      "   0.00040935]\n",
      " ...\n",
      " [ 0.01332552  0.00708654  0.00530958 ...  0.00855762  0.00195742\n",
      "  -0.00734542]\n",
      " [ 0.01040958  0.03193396  0.01094099 ... -0.0047762   0.00987111\n",
      "   0.00334727]\n",
      " [ 0.00582329  0.05109978  0.01250169 ... -0.01728004  0.01103297\n",
      "   0.01655364]] principal components\n",
      "Digit 6: [[-0.00362924 -0.01501189  0.03356172 ... -0.00511689  0.00991964\n",
      "   0.01529559]\n",
      " [-0.00190818 -0.00671312  0.03572574 ... -0.00990831  0.01076838\n",
      "   0.00073983]\n",
      " [-0.00116542 -0.00294988  0.03613087 ... -0.01261263  0.01049265\n",
      "  -0.00126566]\n",
      " ...\n",
      " [ 0.01275253  0.01366803  0.02853459 ... -0.02371468  0.01420665\n",
      "  -0.00503637]\n",
      " [ 0.01038829  0.03176769  0.0302586  ... -0.01380699  0.0045996\n",
      "  -0.0079902 ]\n",
      " [ 0.00609718  0.04011376  0.02043627 ...  0.00650177 -0.00451239\n",
      "  -0.00455583]] principal components\n",
      "Digit 7: [[-3.68898046e-03 -2.97474168e-02  3.60613954e-02 ... -1.47991667e-02\n",
      "   2.94115812e-03 -3.61770733e-03]\n",
      " [-1.71301317e-03 -2.49809445e-02  5.12337630e-02 ... -4.34217455e-05\n",
      "  -8.47386167e-03  1.81336954e-02]\n",
      " [-1.14080833e-03 -2.01602318e-02  4.92857507e-02 ...  3.86043576e-03\n",
      "  -1.05354254e-02  2.30700446e-02]\n",
      " ...\n",
      " [ 1.16095029e-02 -1.02159295e-03 -1.16974800e-02 ... -3.37783063e-03\n",
      "  -4.99297904e-03 -1.74256101e-02]\n",
      " [ 1.09225347e-02  1.32262694e-02 -1.73278825e-02 ...  8.60449051e-03\n",
      "   8.82905035e-03 -8.90805704e-03]\n",
      " [ 8.99913903e-03  3.12211260e-02 -1.68397845e-02 ...  1.54561743e-02\n",
      "   1.10241452e-02 -7.92206920e-03]] principal components\n",
      "Digit 8: [[ 0.00603146  0.00444937 -0.01137998 ...  0.02110191  0.01227631\n",
      "  -0.0129087 ]\n",
      " [ 0.00314111 -0.01342064 -0.02138789 ...  0.00661798 -0.00275413\n",
      "   0.00023451]\n",
      " [ 0.00267309 -0.01698907 -0.01812922 ...  0.0069861  -0.00869906\n",
      "   0.00138619]\n",
      " ...\n",
      " [-0.01159937 -0.00040646  0.00045014 ...  0.00024876 -0.0064721\n",
      "  -0.04073811]\n",
      " [-0.0110507  -0.02042667 -0.00861132 ...  0.00110435  0.00025669\n",
      "  -0.020628  ]\n",
      " [-0.00712909 -0.04148846 -0.02039243 ...  0.00254868  0.01010158\n",
      "   0.00859392]] principal components\n",
      "Digit 9: [[ 0.00406042  0.01054811 -0.01877465 ...  0.01161093 -0.03616203\n",
      "   0.01420984]\n",
      " [ 0.00209486 -0.00153284 -0.00828374 ... -0.0082487  -0.02498318\n",
      "   0.01896839]\n",
      " [ 0.00161581 -0.00587565 -0.00427225 ... -0.00718088 -0.01872452\n",
      "   0.01271571]\n",
      " ...\n",
      " [-0.01096503  0.00166767 -0.00605287 ...  0.01600768 -0.03740332\n",
      "   0.00906403]\n",
      " [-0.00907359 -0.02297725 -0.00130749 ...  0.01961007 -0.03075329\n",
      "   0.00382543]\n",
      " [-0.00524892 -0.04646953  0.00757018 ...  0.01000844 -0.01692084\n",
      "  -0.00385947]] principal components\n"
     ]
    }
   ],
   "source": [
    "# Define PCA function\n",
    "def pca(X, target_var_ratio):\n",
    "    # Standardize the data\n",
    "    X_mean = np.mean(X, axis=0)\n",
    "    X_std = np.std(X, axis=0)\n",
    "    X_standardized = (X - X_mean) / X_std\n",
    "\n",
    "    # Compute covariance matrix\n",
    "    cov_matrix = np.cov(X_standardized, rowvar=False)\n",
    "\n",
    "    # Compute eigenvalues and eigenvectors of the covariance matrix\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "    # Sort eigenvalues and eigenvectors in descending order\n",
    "    idx = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:, idx]\n",
    "\n",
    "    # Compute cumulative explained variance ratio\n",
    "    explained_var_ratio = np.cumsum(eigenvalues) / np.sum(eigenvalues)\n",
    "\n",
    "    # Find the number of principal components that explain target_var_ratio of the variation\n",
    "    num_components = np.argmax(explained_var_ratio >= target_var_ratio) + 1\n",
    "\n",
    "    # Select the top num_components eigenvectors\n",
    "    principal_components = eigenvectors[:, :num_components]\n",
    "\n",
    "    return principal_components\n",
    "\n",
    "# Step 3: Perform PCA for each class in the training data\n",
    "target_var_ratio = 0.9\n",
    "principal_components_per_class = {}\n",
    "\n",
    "for digit in range(10):\n",
    "    # Filter the training data for the current class\n",
    "    X_train_digit = X_train[y_train == digit]\n",
    "\n",
    "    # Perform PCA\n",
    "    principal_components = pca(X_train_digit, target_var_ratio)\n",
    "    principal_components_per_class[digit] = principal_components\n",
    "\n",
    "# Print the number of principal components for each class\n",
    "for digit, components in principal_components_per_class.items():\n",
    "    print(f\"Digit {digit}: {components} principal components\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c40916b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first two principal components: (4096, 2)\n"
     ]
    }
   ],
   "source": [
    "# Define PCA function to return first two principal components\n",
    "def pca_first_two_components(X):\n",
    "    # Standardize the data\n",
    "    X_mean = np.mean(X, axis=0)\n",
    "    X_std = np.std(X, axis=0)\n",
    "    X_standardized = (X - X_mean) / X_std\n",
    "\n",
    "    # Compute covariance matrix\n",
    "    cov_matrix = np.cov(X_standardized, rowvar=False)\n",
    "\n",
    "    # Compute eigenvalues and eigenvectors of the covariance matrix\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "    # Sort eigenvalues and eigenvectors in descending order\n",
    "    idx = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:, idx]\n",
    "\n",
    "    # Select the first two eigenvectors\n",
    "    first_two_components = eigenvectors[:, :2]\n",
    "\n",
    "    return first_two_components\n",
    "\n",
    "# Step 4: Find the first two principal components of the whole training data\n",
    "first_two_components = pca_first_two_components(X_train)\n",
    "\n",
    "# Print the shape of the first two components\n",
    "print(\"Shape of the first two principal components:\", first_two_components.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d4c8faf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m X_train_digit \u001b[38;5;241m=\u001b[39m X_train[y_train \u001b[38;5;241m==\u001b[39m digit]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Perform PCA on the data for the current class to get the first two principal components\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m principal_components \u001b[38;5;241m=\u001b[39m \u001b[43mpca_first_two_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_digit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Project the training data onto the first two principal components\u001b[39;00m\n\u001b[1;32m     11\u001b[0m projected_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X_train_digit, principal_components)\n",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m, in \u001b[0;36mpca_first_two_components\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m      6\u001b[0m X_standardized \u001b[38;5;241m=\u001b[39m (X \u001b[38;5;241m-\u001b[39m X_mean) \u001b[38;5;241m/\u001b[39m X_std\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Compute covariance matrix\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m cov_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_standardized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrowvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Compute eigenvalues and eigenvectors of the covariance matrix\u001b[39;00m\n\u001b[1;32m     12\u001b[0m eigenvalues, eigenvectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meigh(cov_matrix)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/function_base.py:2704\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2702\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2703\u001b[0m     X_T \u001b[38;5;241m=\u001b[39m (X\u001b[38;5;241m*\u001b[39mw)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m-> 2704\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_T\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2705\u001b[0m c \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtrue_divide(\u001b[38;5;241m1\u001b[39m, fact)\n\u001b[1;32m   2706\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class_params = {}\n",
    "\n",
    "for digit in range(10):\n",
    "    # Filter the training data for the current class\n",
    "    X_train_digit = X_train[y_train == digit]\n",
    "\n",
    "    # Perform PCA on the data for the current class to get the first two principal components\n",
    "    principal_components = pca_first_two_components(X_train_digit)\n",
    "\n",
    "    # Project the training data onto the first two principal components\n",
    "    projected_data = np.dot(X_train_digit, principal_components)\n",
    "\n",
    "    # Compute mean and covariance matrix of the projected data\n",
    "    mean = np.mean(projected_data, axis=0)\n",
    "    covariance_matrix = np.cov(projected_data, rowvar=False)\n",
    "\n",
    "    # Store mean and covariance matrix in a dictionary\n",
    "    class_params[digit] = {'mean': mean, 'covariance_matrix': covariance_matrix, 'principal_components': principal_components}\n",
    "\n",
    "# Print the parameters for each class\n",
    "for digit, params in class_params.items():\n",
    "    print(f\"Digit {digit}:\")\n",
    "    print(\"Mean:\", params['mean'])\n",
    "    print(\"Covariance Matrix:\")\n",
    "    print(params['covariance_matrix'])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c667cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Initialize variables to store predicted labels and correct predictions count\n",
    "predicted_labels = []\n",
    "correct_predictions = 0\n",
    "\n",
    "# Loop through each data point in the test set\n",
    "for i in range(len(X_test)):\n",
    "    data_point = X_test[i]\n",
    "    true_label = y_test[i]\n",
    "    \n",
    "    # Initialize variables to store likelihoods for each class\n",
    "    likelihoods = []\n",
    "    \n",
    "    # Compute likelihood for each class\n",
    "    for digit in range(10):\n",
    "        # Get parameters of the current class\n",
    "        mean = class_params[digit]['mean']\n",
    "        covariance_matrix = class_params[digit]['covariance_matrix']\n",
    "        principal_components = class_params[digit]['principal_components']\n",
    "        \n",
    "        # Project the data point onto the first two principal components of the current class\n",
    "        projected_data = np.dot(data_point, principal_components)\n",
    "        \n",
    "        # Compute likelihood using multivariate normal distribution\n",
    "        likelihood = multivariate_normal.pdf(projected_data, mean=mean, cov=covariance_matrix)\n",
    "        likelihoods.append(likelihood)\n",
    "    \n",
    "    # Classify the data point based on the class with the highest likelihood\n",
    "    predicted_label = np.argmax(likelihoods)\n",
    "    predicted_labels.append(predicted_label)\n",
    "    \n",
    "    # Check if the predicted label matches the true label\n",
    "    if predicted_label == true_label:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Calculate success rate\n",
    "success_rate = correct_predictions / len(X_test)\n",
    "print(\"Success rate of the classification method:\", success_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d97a29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592c7deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
